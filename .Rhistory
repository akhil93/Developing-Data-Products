test_id = test$PassengerId
predictions$test_id = 1
}
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data=train, method="class")
library(rpart)
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data=train, method="class")
train <- read.csv("train.csv")
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data=train, method="class")
plot(fit)
text(fit)
install.packages('rattle')
install.packages('rpart.plot')
install.packages('RColorBrewer')
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(fit)
library(fancyRpartPlot)
fancyRpartPlot(fit)
fancyRpart.Plot(fit)
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data=train,
method="class", control=rpart.control(minsplit=2, cp=0))
fancyRpartPlot(fit)
library(rattle)
fancy.RpartPlot(fit)
x = [5.57,6.33,6.31,6.12,7.14,7.04,7.20]
x = c(5.57,6.33,6.31,6.12,7.14,7.04,7.20)
plot(x, type = "l")
data.dir   <- '~/Documents/project/Kaggle/'
train.file <- paste0(data.dir, 'training.csv')
test.file <- paste0(data.dir, 'test.csv')
d.train <- read.csv(train.file, stringsAsFactors = F)
d.train <- read.csv(train.file, stringsAsFactors=F)
d.train <- read.csv('C:/Users/Akhilkumar/Documents/Documents/project/Kaggle/training.csv', stringsAsFactors=F)
d.train <- read.csv(train.file, stringsAsFactors=False)
d.train <- read.csv(file.choose(), stringsAsFactors=False)
d.train <- read.csv(file.choose(), stringsAsFactors=F)
str(d.train)
head(d.train)
im.train <- d.train$Image
d.train$Image <- NULL
head(d.train)
im.train[1]
install.packages('foreach')
im.train <- foreach(im = im.train, .combine=rbind) %dopar% {
as.integer(unlist(strsplit(im, " ")))
}
im.train <- foreach(im = im.train, .combine=rbind) %do% {
as.integer(unlist(strsplit(im, " ")))
}
library(foreach)
library(foreach)
install.packages('foreach')
library(foreach)
im.train <- foreach(im = im.train, .combine=rbind) %do% {
as.integer(unlist(strsplit(im, " ")))
}
str(im.train)
d.test  <- read.csv(test.file, stringsAsFactors=F)
d.test  <- read.csv(file.choose(), stringsAsFactors=F)
im.test <- foreach(im = d.test$Image, .combine=rbind) %dopar% {
as.integer(unlist(strsplit(im, " ")))
}
im.test <- foreach(im = d.test$Image, .combine=rbind) %do% {
as.integer(unlist(strsplit(im, " ")))
}
d.test$Image <- NULL
save(d.train, im.train, d.test, im.test, file='data.Rd')
im <- matrix(data=rev(im.train[1,]), nrow=96, ncol=96)
image(1:96, 1:96, im, col = gray((0:255)/255))
points(96-d.train$nose_tip_x[1],96-d.train$nose_tip_y[1],col="red")
points(96-d.train$left_eye_center_x[1],96-d.train$left_eye_center_y[1],col="blue")
points(96-d.train$right_eye_center_x[1],96-d.train$right_eye_center_y[1],col="green")
for(i in 1:nrow(d.train)) {
points(96-d.train$nose_tip_x[i], 96-d.train$nose_tip_y[i], col="red")
}
idx <- which.max(d.train$nose_tip_x)
im  <- matrix(data=rev(im.train[idx,]), nrow=96, ncol=96)
image(1:96, 1:96, im, col=gray((0:255)/255))
points(96-d.train$nose_tip_x[idx], 96-d.train$nose_tip_y[idx], col="red")
getwd
getwd()
homicides <- readLines("~/Books/courserahomicides.txt");
homicides <- readLines("Books/courserahomicides.txt");
homicides <- readLines("Books/coursera/homicides.txt");
agecount(23)
agecount(3)
agecount(3);
source('~/.active-rstudio-document')
agecount(3)
agecount(21)
source('~/.active-rstudio-document')
best("TX", "heart attack")
source('C:/Users/Akhilkumar/Downloads/Computing for data analytics/Complete.R')
source('~/Computing for data analytics/rankall.R')
rankall("heart attack")
rankall("heart attack", num = "best")
pnorm(24, mean = 21, sd = 5)
qnorm(0.90, mean = 1500, sd = 300)
qnorm(0.10, mean = 21, sd = 5)
x <- c(4,5,6,7,8,9,10)
dnorm(x, 7, 1)
plot(x, dnorm(x, 7, 1), type = "l")
plot(x, dnorm(x, 7, 1), type = "l", lwd = 2)
dbinorm(.56, 10, 2)
dbinom(.56, 10, 2)
dbinom(2, 10, .56)
hist(dbinom(2, 10, .56))
pnorm(34, mean = 24, sd = 4)
choose(4,1)
choose(10,0)
sum(dbinom(60:160, size = 160, p = .28))
sum(dbinom(50:160, size = 160, p = .28))
qnorm(0.01)
qnorm(0.0066666666666667)
qnorm(0.05)
pnorm(70,80,10)
pnorm(70,80,10, lower.tail = TRUE)
qnorm(.95,1100,75)
qnorm(95,1100,75)
qnorm(.95,1100,75, lower.tail = FALSE)
ppois(10,lamda = 5*3)
ppois(10,lambda = 5*3)
pnorm(70,80,10, lower.tail = TRUE)
1-0.8413
qnorm(.95,1100,75)
qnorm(.95,1100,75, lower.tail = TRUE)
qnorm(.95,1100,75, lower.tail = FALSE)
dnorm(.95,1100,75, lower.tail = FALSE)
dnorm(.95,1100,75)
ppois(10,lambda = 5*3)
qnorm(.95,1100,75, lower.tail = TRUE)
MEAN = 0
for(i in 1:100){
a = qnorm(.95,1100,75, lower.tail = TRUE)
MEAN = MEAN + a
}
MEAN
pnorm(70,80,10)
qnorm(70,80,10)
pnorm(14,15,10)
0.4601722*2
pnorm(14:16,15,10)
0.5398278-0.4601722
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
summary(training)
plot(training$CompressiveStrength)
plot(training$FlyAsh)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
29/40
View(training)
grep("IL",colnames(training))
13*.8
new = princomp(training)
new = princomp(~., data =training)
new = training[,c(2,grep("IL",colnames(training)))]
prepro = preProcess(training,method = "pca", pcaComp = 2)
prepro = preProcess(training[,-1],method = "pca", pcaComp = 2)
summary(head(training[,1]))
modelFit <- train(training$diagnosis ~ .,method="glm",data=training)
summary(modelFit)
modelFit
hist(log(training$Superplasticizer))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(log(training$Superplasticizer))
summary(log(training$Superplasticizer))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
pairs(training)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
grep("IL",colnames(training))
new = training[, grep("IL",colnames(training))]
modelFit <- train(~ .,method="glm",preProcess="pca",data=training)
hist(log(training$Superplasticizer))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(log(training$Superplasticizer))
hist(log(training$Superplasticizer+1))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
preProc<-preProcess(smalltrain[,-1],method="pca")
trainPC<-predict(preProc,smalltrain[,-1])
SELECT<-which(grepl("^IL|^diagnosis", colnames(training), ignore.case = T))
smalltrain<-training[,SELECT]
preProc<-preProcess(smalltrain[,-1],method="pca")
trainPC<-predict(preProc,smalltrain[,-1])
grep("IL",colnames(training))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
grep("IL",colnames(training))
View(training)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
grep("IL",colnames(training))
smalltrain<-training[,(grepl("^IL|^diagnosis", colnames(training), ignore.case = T)]
select = which((grepl("^IL|^diagnosis", colnames(training), ignore.case = T))
)
select = which((grepl("^IL|^diagnosis", colnames(training), ignore.case = T)))
SELECT<-which(grepl("^IL|^diagnosis", colnames(training), ignore.case = T))
smalltrain<-training[,SELECT]
preProc<-preProcess(smalltrain[,-1],method="pca")
trainPC<-predict(preProc,smalltrain[,-1])
trainPC
summary(trainPC)
modelFit<-train(smalltrain$diagnosis~.,method="glm",data=trainPC)
modelFit
summary(modelFit)
9*.8
getwd()
data(mtcars)
summary(mtcars)
str(mtcars)
mtcars$am = as.factor(mtcars$am)
str(mtcars)
View(mtcars)
summary(mtcars$am)
par(mfrow = c(1,2))
hist(mtcars$am == 0, col = "steelblue")
hist(mtcars$am == "0", col = "steelblue")
hist(as.numeric(mtcars$am == "0"), col = "steelblue")
hist( mpg[which(as.numeric(mtcars$am == "0")], col = "steelblue" )
hist( mpg[which(as.numeric(mtcars$am == "0"))], col = "steelblue" )
hist( mtcars$mpg[which(as.numeric(mtcars$am == "0"))], col = "steelblue" )
mtcars$automatic = mtcars$am == 0
par(mfrow = c(1,2))
hist( mpg[which(automatic == TRUE)], data = mtcars, col = "steelblue" )
hist( mtcars$mpg[which(mtcars$automatic == TRUE)], col = "steelblue" )
hist( mtcars$mpg[which(mtcars$automatic == FALSE)], col = "steelblue" )
plot( mtcars$mpg[which(mtcars$automatic == FALSE)], col = "steelblue" )
plot( mtcars$mpg[which(mtcars$automatic == TRUE)], col = "red" )
max(mtcars$mpg[which(mtcars$automatic == TRUE)])
max(mtcars$mpg[which(mtcars$automatic == FALSE)])
model = lm(mpg ~ wt, data = mtcars)
summary(model)
model = lm(mpg ~ automatic, data = mtcars)
summary(model)
model = lm(mpg ~ automatic == FALSE, data = mtcars)
summary(model)
model2 = lm(mpg ~ wt + automatic, data = mtcars)
summary(model2)
model.fs = lm(automatic ~ wt, data = mtcars) # first stage.
model.IV = lm( mpg ~ model.fs$fitted.values, data = mtcars)
summary(model.IV)
par(mfrow = c(1,2))
hist( model$residuals )
hist( model.IV$residuals )
render("MotorTrend.Rmd", "MotorTrend.pdf")
pandoc(MotorTrend.Rmd, format = "pdf")
library(knitr)
pandoc(MotorTrend.Rmd, format = "pdf")
render("MotorTrend.Rmd", "MotorTrend.pdf")
pandoc(MotorTrend.Rmd, format = "pdf")
pandoc(MotorTrend.Rmd, format = "pdf")
sessionInfo()
?shuttle
install.packages("MASS")
?shuttle
library(MASS)
?shuttle
data(shuttle)
str(shuttle)
table(shuttle$use)
summary(glm(shuttle$use == "auto" ~ shuttle$wind , family="binomial"))
qm1 = glm(shuttle$use == "auto" ~ shuttle$wind , family="binomial")
qm1
exp(qm1$coeff)
exp(confint(qm1$coeff))
exp(confint(qm1))
summary(glm(shuttle$use ~ shuttle$wind + shuttle$magn, family="binomial"))
qm2 = glm(shuttle$use ~ shuttle$wind + shuttle$magn, family="binomial")
exp(qm2$coeff)
confint(exp(qm2))
exp(confint(qm2))
levels(shuttle$use) = c(0,1)
str(shuttle)
table(shuttle$use)
qm1 = glm(shuttle$use == 1 ~ shuttle$wind, family = binomial)
summary(qm1)
qm1 = glm(shuttle$use == 1 ~ as.factor(shuttle$wind), family = binomial)
summary(qm1)
qm1 = glm(shuttle$use == 1 ~ shuttle$wind == "head", family = binomial)
summary(qm1)
qm1 = glm(shuttle$use == 1 ~ shuttle$wind == 0, family = binomial)
summary(qm1)
summary(logRegshuttle <- glm(use ~ wind,family="binomial", data=shuttle ))
logRegshuttle <- glm(use ~ wind,family="binomial", data=shuttle )
exp(logRegshuttle)/(1-exp(logRegshuttle))
exp(logRegshuttle$coeff)/(1-exp(logRegshuttle$coeff))
str(shuttle)
levels(shuttle$wind) = c("head","tail")
str(shuttle)
logRegshuttle <- glm(use ~ as.factor(wind),family="binomial", data=shuttle )
summary(logRegshuttle)
.25131/.03181
exp(-0.25131)/exp(-0.03181)
rm(shuttle)
rm(logRegshuttle,qm1,qm2)
data(shuttle)
str(shuttle)
summary(glm(shuttle$use ~ shuttle$wind + shuttle$magn, family="binomial"))
summary(glm(use ~ wind, data = shuttle, family = "binomial"))
summary(glm(use ~ wind-1, data = shuttle, family = "binomial"))
exp(-0.2513)/(exp(-0.2831))
exp(-0.2513)/exp(-0.2831)
exp(-0.2513)/(1-exp(-0.2831))
data(InsectSprays)
str(InsectSprays)
summary(glm(count ~ as.factor(spray), data = InsectSprays,family = "poission"))
summary(glm(count ~ as.factor(spray), data = InsectSprays,family = "poisson"))
summary(glm(count ~ as.factor(spray)-1, data = InsectSprays,family = "poisson"))
exp(2.67415)/exp(2.73003)
summary(glm(use ~ wind-1, data = shuttle))
data(shuttle)
str(shuttle)
summary(glm(use ~ wind-1, data = shuttle))
summary(glm(use ~ wind, data = shuttle))
summary(glm(use ~ wind-1, data = shuttle, family = "binomial"))
exp(-0.2513)/exp(-0.2831)
summary(glm(shuttle$use ~ shuttle$wind + shuttle$magn, family="binomial"))
summary(glm(shuttle$use ~ shuttle$wind + shuttle$magn-1, family="binomial"))
exp(-3.635e-01)/exp(-3.955e-01)
exp(-3.635e-01 )/exp(-3.201e-02)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
str(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
str(vowel.train)
str(vowel.test)
library(caret)
train(y ~., data = vowel.train, method = "randomForest")
set.seed(33833)
train(y ~., data = vowel.train, method = "gbm")
model = train(y ~., data = vowel.train, method = "gbm")
model = train(y ~., data = vowel.train, method = "rf")
rf.ped = predict(model, newdata = vowel.test)
summary(rf.ped)
table(rf.ped, vowel.test)
model = randomForest(y ~., data = vowel.train)
model
p = predict(model, vowel.test)
table(p,vowel.test )
table(p,vowel.test)
table(p,vowel.test$y)
sum(diag(table(p,vowel.test$y)))
277/462
model = gbm(y ~., data = vowel.train)
p = predict(model, vowel.test)
sum(diag(table(p,vowel.test$y)))
model = gbm(y ~., data = vowel.train, n.tree = 100)
p = predict(model, vowel.test)
table(p,vowel.test$y)
model = train(y ~., data = vowel.train, method = "randomForest")
model = train(y ~., data = vowel.train, method = "RF")
model = train(y ~., data = vowel.train, method = "rf")
p = predict(model, vowel.test)
table(p,vowel.test$y)
sum(diag(table(p,vowel.test$y)))/462
model = train(y ~., data = vowel.train, method = "gbm")
library(MASS)
?shuttle
data(shuttle)
str(shuttle)
names(shuttle)
?glm
fit <- glm(use ~ wind, family='binomial', shuttle)
exp(fit$coeff)
fit <- glm(use ~ wind + as.factor(magn), family='binomial', shuttle)
exp(fit$coeff)
0.7777778/0.9686888
0.6952323 /0.9684981
data(InsectSprays)
outp <- exp(coef(glm(count ~ as.factor(spray) - 1, family="poisson", InsectSprays)))
outp
outp[1]/outp[2]
?offset
log(10)
glm(count ~ x + offset(t), family = poisson)
library(ElemStatLearn)
library(plyr)
data(vowel.train)
data(vowel.test)
vowel.train <- mutate(vowel.train,y=factor(y))
vowel.test <- mutate(vowel.test,y=factor(y))
library(caret)
set.seed(33833)
rf.mdl <- train(y~.,data=vowel.train,method="rf",verbose=FALSE,metric="Accuracy")
gbm.mdl <- train(y~.,data=vowel.train,method="gbm",verbose=FALSE,metric="Accuracy")
pred.rf <- predict(rf.mdl,vowel.test)
pred.gbm <- predict(gbm.mdl,vowel.test)
confusionMatrix(pred.rf,vowel.test$y)$overall["Accuracy"]
confusionMatrix(pred.gbm,vowel.test$y)$overall["Accuracy"]
idx <- pred.rf == pred.gbm
pred.comb <- pred.rf[idx]
test.comb <- vowel.test[idx,"y"]
confusionMatrix(pred.comb,test.comb)$overall["Accuracy"]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso.mdl <- train(CompressiveStrength~.,data=training,method="lasso",
metric="RMSE")
plot(lasso.mdl$finalModel,xvar="penalty",use.color=TRUE)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso.mdl <- train(CompressiveStrength~.,data=training,method="lasso",
metric="RMSE")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso.mdl <- train(CompressiveStrength~.,data=training,method="lasso",
metric="RMSE")
install.packages("elasticnet")
install.packages("yhat")
library(yhat)
install.packages("yhatr")
library(yhatr)
getwd()
setwd("C:/Users/Akhilkumar/Documents/Developing-Data-Products")
setwd("C:/Users/Akhilkumar/Documents/Developing-Data-Products/")
getwd()
setwd("~/GitHub/Developing-Data-Products")
shiny::runApp()
deployApp()
library(shinyapps)
deployApp()
shiny::runApp()
shiny::runApp()
